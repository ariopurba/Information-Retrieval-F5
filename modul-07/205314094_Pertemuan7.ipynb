{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from importlib import import_module\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import copy\n",
    "import string\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "np.random.seed(123456789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# !pip install ipython-autotime\n",
    "\n",
    "# %load_ext autotime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ekstrak Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"../Modul7//doc.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# parse csv data doc.csv \n",
    "paths = []\n",
    "\n",
    "# buka file csv\n",
    "with open(title, 'r') as file:\n",
    "    # membaca file csv\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    # lewati header\n",
    "    next(csv_reader)\n",
    "    \n",
    "    # loop setiap bari dari dalam file csv\n",
    "    for row in csv_reader:\n",
    "        # ambil nilai pada kolom \"sentences\" dan tambahkan ke array\n",
    "        sentence = row[1]\n",
    "        paths.append(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Atomic Habits karya James Clear, merupakan salah satu buku self improvement yang mengajarkan bagaimana caranya membangun kebiasaan baik dan meninggalkan kebiasaan buruk.', 'Dalam buku ini menerangkan mengenai memperoleh hasil yang luar biasa dengan mengubah rutinitas-rutinitas kecil yang baik.', 'Perubahan-perubahan kecil ini akan menjadikan kita luar biasa jika kita praktekan secara telaten dan terus-menerus.', 'Seseorang yang memiliki habits baik dalam dirinya, memiliki kecenderungan lebih sukses daripada seseorang yang memiliki habits buruk.', 'James Clear mengambil contoh dalam olahraga sepeda di Britania Raya, dimana dapat mengubah grup nya yang awalnya biasa saja menjadi juara Tour de France sebanyak 5 kali dalam 6 tahun berturut-turut.', 'Ia menjelaskan bahwa untuk mendapatkan kemenangan tersebut Dave hanya mengubah hal-hal kecil dan terkesan sepele.', 'Dimana dia mecoba mendesain ulang tempat duduk sepeda agar lebih nyaman ketika digunakan dan menyuruh seluruh tim-nya untuk memakai celana  yang dapat menjaga suhu tubuh mereka agar tetap hangat.', 'Perubahan-perubahan kecil yang atomic semacam ini yang dapat membawa perubahan besar terhadap reputasi tim Dave.', 'Zona nyaman memberikan kalian efek nyaman, rileks, dan juga stabil tanpa gangguan.', 'Pengaruh tersebut dikarenakan bahwa otak memproduksi senyawa dopamine & serotonin ketika kalian merasa nyaman.']\n"
     ]
    }
   ],
   "source": [
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(paths))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(data):\n",
    "    try:\n",
    "        ind = data.index('\\n\\n')\n",
    "        data = data[ind:]\n",
    "    except:\n",
    "        print(\"No Header\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return np.char.strip(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_single_characters(data):\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return np.char.strip(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers(data):\n",
    "    data = np.char.replace(data, \"0\", \" zero \")\n",
    "    data = np.char.replace(data, \"1\", \" one \")\n",
    "    data = np.char.replace(data, \"2\", \" two \")\n",
    "    data = np.char.replace(data, \"3\", \" three \")\n",
    "    data = np.char.replace(data, \"4\", \" four \")\n",
    "    data = np.char.replace(data, \"5\", \" five \")\n",
    "    data = np.char.replace(data, \"6\", \" six \")\n",
    "    data = np.char.replace(data, \"7\", \" seven \")\n",
    "    data = np.char.replace(data, \"8\", \" eight \")\n",
    "    data = np.char.replace(data, \"9\", \" nine \")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return np.char.strip(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, query):\n",
    "    if not query:\n",
    "        data = remove_header(data)        \n",
    "    data = convert_lower_case(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_stop_words(data)\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_single_characters(data)\n",
    "    data = stemming(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buat Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Header\n",
      "0\n",
      "No Header\n",
      "No Header\n",
      "No Header\n",
      "No Header\n",
      "No Header\n",
      "No Header\n",
      "No Header\n",
      "No Header\n",
      "No Header\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
      "C:\\Users\\ariop\\AppData\\Local\\Temp\\ipykernel_11540\\1556671103.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  frequency.insert(value=[1], loc=0, column=token)\n"
     ]
    }
   ],
   "source": [
    "postings = pd.DataFrame()\n",
    "frequency = pd.DataFrame()\n",
    "doc = 0\n",
    "\n",
    "for path in paths:\n",
    "    preprocessed_text = preprocess(path, False)\n",
    "    if doc%100 == 0:\n",
    "        print(doc)\n",
    "    tokens = word_tokenize(str(preprocessed_text))\n",
    "\n",
    "    pos = 0\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in postings:\n",
    "            p = postings[token][0]\n",
    "\n",
    "            k = [a[0] for a in p]\n",
    "\n",
    "            if doc in k:\n",
    "                for a in p:\n",
    "                    if a[0] == doc:\n",
    "                        a[1].add(pos)\n",
    "            else:\n",
    "                p.append([doc,{pos}])\n",
    "                frequency[token][0] += 1\n",
    "        else:\n",
    "            postings.insert(value=[[[doc, {pos}]]], loc=0, column=token)\n",
    "            frequency.insert(value=[1], loc=0, column=token)\n",
    "        pos += 1\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_postings(word):\n",
    " preprocessed_word = str(preprocess(word, True))\n",
    " print(preprocessed_word)\n",
    " print(\"Frequency:\",frequency[preprocessed_word][0])\n",
    " print(\"Postings List:\",postings[preprocessed_word][0])\n",
    " total=0\n",
    " #total\n",
    " for x in postings[preprocessed_word][0]:\n",
    "    total+=len(x)\n",
    " #Print probability\n",
    " i=1\n",
    " for x in postings[preprocessed_word][0]:\n",
    "    prob=len(x)/total\n",
    " print(\"Document \",i,\":\",prob)\n",
    " i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11540\\176618833.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mzip_jm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11540\\176618833.py\u001b[0m in \u001b[0;36mzip_jm\u001b[1;34m(x, lambda_)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m  \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkata\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kata' is not defined"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.5\n",
    "def zip_jm(x, lambda_=lambda_):\n",
    " if lambda_ < 0 or lambda_ > 1 :\n",
    "    return np.zeros_like(x)\n",
    " else:\n",
    "    return (x == 0) * (1-lambda_) * (kata/d) + lambda_ * c\n",
    "\n",
    "\n",
    "\n",
    "zip_jm(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "xs = np.arange(0, 10);\n",
    "palette = sns.color_palette()\n",
    "ax.bar(2.5 * xs, stats.poisson.pmf(xs, lambda_), width=0.9,\n",
    "color=palette[0], label='Poisson');\n",
    "ax.bar(2.5 * xs + 1, zip_pmf(xs), width=0.9, color=palette[1],\n",
    "label='Zero-inflated Poisson');\n",
    "ax.set_xticks(2.5 * xs + 1);\n",
    "ax.set_xticklabels(xs);\n",
    "ax.set_xlabel('$x$');\n",
    "ax.set_ylabel('$P(X = x)$');\n",
    "ax.legend();\n",
    "N = 1000\n",
    "inflated_zero = stats.bernoulli.rvs(pi, size=N)\n",
    "x = (1 - inflated_zero) * stats.poisson.rvs(lambda_, size=N)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.hist(x, width=0.8, bins=np.arange(x.max() + 1), normed=True);\n",
    "ax.set_xticks(np.arange(x.max() + 1) + 0.4);\n",
    "ax.set_xticklabels(np.arange(x.max() + 1));\n",
    "ax.set_xlabel('$x$');\n",
    "ax.set_ylabel('Proportion of samples');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81ac62153dbc0a1bc311088bfbe972f5bbc7cf4d6a509b29cbf21106c5927a31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
