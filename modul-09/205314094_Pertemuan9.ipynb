{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laporan Modul 9\n",
    "Nama = Ario Tua Purba<br>\n",
    "NIM = 205314094\n",
    "\n",
    "Membuat Program Analisis Sentiment\n",
    "\n",
    "Sentiment analysis adalah proses penggunaan text analytics untuk mendapatkan berbagai sumber data dari internet dan beragam platform media sosial. Tujuannya adalah untuk memperoleh opini dari pengguna yang terdapat pada platform tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\ariop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy as nltk_accuracy\n",
    "import nltk\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to construct a dictionary object based on the input words and return it\n",
    "\n",
    "# Extract features from the input list of words\n",
    "def extract_features(words):\n",
    "    return dict([word, True] for word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of training datapoints: 1600\n",
      "Number of test datapoints: 400\n",
      "\n",
      "Accuracy of the classifer: 0.735\n",
      "\n",
      "Top 15 most informative words:\n",
      "1. outstanding\n",
      "2. insulting\n",
      "3. vulnerable\n",
      "4. ludicrous\n",
      "5. uninvolving\n",
      "6. astounding\n",
      "7. avoids\n",
      "8. fascination\n",
      "9. affecting\n",
      "10. animators\n",
      "11. anna\n",
      "12. darker\n",
      "13. seagal\n",
      "14. symbol\n",
      "15. idiotic\n",
      "\n",
      "Movie review predictions:\n",
      "\n",
      "Review: The customes in this movies were great\n",
      "\n",
      "Review: I think the story was terrible and the characters were very weak\n",
      "\n",
      "Review: People say that the director of the movie is amazing\n",
      "\n",
      "Review: This is such an idiotic movie. I will not recomend it to anyone.\n",
      "Predicted sentiment:  Negative\n",
      "Probabilities:  0.89\n"
     ]
    }
   ],
   "source": [
    "# Define the main function and load the labeled movie reviews:\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # load the reviews from the corpus\n",
    "    fileids_pos = movie_reviews.fileids('pos')\n",
    "    fileids_neg = movie_reviews.fileids('neg')\n",
    "    # extract the features from the reviews\n",
    "    features_pos = [(extract_features(movie_reviews.words(\n",
    "        fileids =[f])), 'Positive') for f in fileids_pos]\n",
    "    features_neg = [(extract_features(movie_reviews.words(\n",
    "        fileids =[f])), 'Negative') for f in fileids_neg]\n",
    "    \n",
    "    # define the train and test split (80% and 20%)\n",
    "    threshold = 0.8\n",
    "    num_pos = int(threshold * len(features_pos))\n",
    "    num_neg = int(threshold * len(features_neg))\n",
    "    \n",
    "    # Create training and training datasets\n",
    "    features_train = features_pos[:num_pos] + features_neg[:num_neg]\n",
    "    features_test = features_pos[num_pos:] + features_neg[num_neg:]\n",
    "    \n",
    "    # print the number of datapoints used \n",
    "    print('\\nNumber of training datapoints:', len(features_train))\n",
    "    print('Number of test datapoints:', len(features_test))\n",
    "    \n",
    "    # Trains a Naive Bayes classifier\n",
    "    classifier = NaiveBayesClassifier.train(features_train)\n",
    "    print('\\nAccuracy of the classifer:', nltk_accuracy(classifier, features_test))\n",
    "    \n",
    "    # Print the top N most informastive words\n",
    "    N = 15\n",
    "    print('\\nTop '+str(N)+ ' most informative words:')\n",
    "    for i, item in enumerate(classifier.most_informative_features()):\n",
    "        print(str(i+1) + '. '+item[0])\n",
    "        if i == N - 1:\n",
    "            break\n",
    "    # Test input movies reviews\n",
    "    input_reviews = [\n",
    "        'The customes in this movies were great',\n",
    "        'I think the story was terrible and the characters were very weak',\n",
    "        'People say that the director of the movie is amazing',\n",
    "        'This is such an idiotic movie. I will not recomend it to anyone.'\n",
    "    ]\n",
    "    \n",
    "    # iterate through the sample data and predict the output\n",
    "    print(\"\\nMovie review predictions:\")\n",
    "    for review in input_reviews:\n",
    "        print(\"\\nReview:\", review)\n",
    "    \n",
    "    # Compute the probabilities\n",
    "    probabilities = classifier.prob_classify(extract_features(review.split()))\n",
    "    \n",
    "    # pick the minimum value\n",
    "    prediceted_sentiment = probabilities.max()\n",
    "    \n",
    "    # print the outputs (positive or negative sentiment)\n",
    "    print(\"Predicted sentiment: \", prediceted_sentiment)\n",
    "    print(\"Probabilities: \", round(probabilities.prob(prediceted_sentiment), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of training datapoints: 1600\n",
      "Number of test datapoints: 400\n",
      "\n",
      "Accuracy of the classifier: 0.735\n",
      "\n",
      "Top 15 most informative words:\n",
      "1. outstanding\n",
      "2. insulting\n",
      "3. vulnerable\n",
      "4. ludicrous\n",
      "5. uninvolving\n",
      "6. astounding\n",
      "7. avoids\n",
      "8. fascination\n",
      "9. affecting\n",
      "10. animators\n",
      "11. anna\n",
      "12. darker\n",
      "13. seagal\n",
      "14. symbol\n",
      "15. idiotic\n",
      "\n",
      "Movie review predictions:\n",
      "\n",
      "Review: The costumes in this movie were great\n",
      "Predicted sentiment: Positive\n",
      "Probability: 0.59\n",
      "\n",
      "Review: I think the story was terrible and the characters were very weak\n",
      "Predicted sentiment: Negative\n",
      "Probability: 0.8\n",
      "\n",
      "Review: People say that the director of the movie is amazing\n",
      "Predicted sentiment: Positive\n",
      "Probability: 0.6\n",
      "\n",
      "Review: This is such an idiotic movie. I will not recommend it to anyone.\n",
      "Predicted sentiment: Negative\n",
      "Probability: 0.87\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    # Load the reviews from the corpus \n",
    "    fileids_pos = movie_reviews.fileids('pos')\n",
    "    fileids_neg = movie_reviews.fileids('neg')\n",
    "     \n",
    "    # Extract the features from the reviews\n",
    "    features_pos = [(extract_features(movie_reviews.words(\n",
    "            fileids=[f])), 'Positive') for f in fileids_pos]\n",
    "    features_neg = [(extract_features(movie_reviews.words(\n",
    "            fileids=[f])), 'Negative') for f in fileids_neg]\n",
    "     \n",
    "    # Define the train and test split (80% and 20%)\n",
    "    threshold = 0.8\n",
    "    num_pos = int(threshold * len(features_pos))\n",
    "    num_neg = int(threshold * len(features_neg))\n",
    "     \n",
    "     # Create training and training datasets\n",
    "    features_train = features_pos[:num_pos] + features_neg[:num_neg]\n",
    "    features_test = features_pos[num_pos:] + features_neg[num_neg:]  \n",
    "\n",
    "    # Print the number of datapoints used\n",
    "    print('\\nNumber of training datapoints:', len(features_train))\n",
    "    print('Number of test datapoints:', len(features_test))\n",
    "     \n",
    "    # Train a Naive Bayes classifier \n",
    "    classifier = NaiveBayesClassifier.train(features_train)\n",
    "    print('\\nAccuracy of the classifier:', nltk_accuracy(\n",
    "            classifier, features_test))\n",
    "\n",
    "    N = 15\n",
    "    print('\\nTop ' + str(N) + ' most informative words:')\n",
    "    for i, item in enumerate(classifier.most_informative_features()):\n",
    "        print(str(i+1) + '. ' + item[0])\n",
    "        if i == N - 1:\n",
    "            break\n",
    "\n",
    "    # Test input movie reviews\n",
    "    input_reviews = [\n",
    "        'The costumes in this movie were great', \n",
    "        'I think the story was terrible and the characters were very weak',\n",
    "        'People say that the director of the movie is amazing', \n",
    "        'This is such an idiotic movie. I will not recommend it to anyone.' \n",
    "    ]\n",
    "\n",
    "    print(\"\\nMovie review predictions:\")\n",
    "    for review in input_reviews:\n",
    "        print(\"\\nReview:\", review)\n",
    "\n",
    "        # Compute the probabilities\n",
    "        probabilities = classifier.prob_classify(extract_features(review.split()))\n",
    "\n",
    "        # Pick the maximum value\n",
    "        predicted_sentiment = probabilities.max()\n",
    "\n",
    "        # Print outputs\n",
    "        print(\"Predicted sentiment:\", predicted_sentiment)\n",
    "        print(\"Probability:\", round(probabilities.prob(predicted_sentiment), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81ac62153dbc0a1bc311088bfbe972f5bbc7cf4d6a509b29cbf21106c5927a31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
